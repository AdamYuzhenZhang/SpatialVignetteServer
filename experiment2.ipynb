{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314ae51e",
   "metadata": {},
   "source": [
    "# Abstraction and Texturing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e02f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer\n",
      "Testing Vignette: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from pipeline.vignette_data import ProcessedVignette\n",
    "from typing import Dict, Any, Optional, List\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "# get the root for importing test data\n",
    "os.environ[\"SAM_BACKEND\"] = \"coreml\"\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Configuration\n",
    "VIGNETTE_NAME = \"capture2\"\n",
    "VIGNETTE_PATH = project_root / \"test_data\" / VIGNETTE_NAME\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Testing Vignette: {VIGNETTE_PATH}\")\n",
    "\n",
    "# Paths for the inputs and outputs\n",
    "rgb_path = VIGNETTE_PATH / \"rgb.png\"\n",
    "metadata_path = VIGNETTE_PATH / \"metadata.json\"\n",
    "results_path = VIGNETTE_PATH / \"results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac8f91",
   "metadata": {},
   "source": [
    "## Texturing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f24ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points_to_2d(points_3d, intrinsics):\n",
    "    \"\"\"Projects 3D points (in original camera space) to 2D image coordinates.\"\"\"\n",
    "    projected = intrinsics @ points_3d.T\n",
    "    d = projected[2, :] + 1e-6\n",
    "    u = projected[0, :] / d\n",
    "    v = projected[1, :] / d\n",
    "    return np.vstack((u, v)).T\n",
    "\n",
    "def plane_equation_to_point_normal(equation, fallback_point):\n",
    "    \"\"\"Derives a point and normal from a plane equation [a,b,c,d].\"\"\"\n",
    "    normal = equation[:3]\n",
    "    normal_norm = np.linalg.norm(normal)\n",
    "    if normal_norm == 0: return fallback_point, np.array([0,0,1])\n",
    "    normal = normal / normal_norm\n",
    "    v = fallback_point - np.array([0, 0, 0])\n",
    "    dist = np.dot(v, normal) + equation[3]\n",
    "    point_on_plane = fallback_point - dist * normal\n",
    "    return point_on_plane, normal\n",
    "\n",
    "\n",
    "def find_minimum_bounding_rectangle(points_2d):\n",
    "    \"\"\"Finds the minimum area bounding rectangle for a set of 2D points.\"\"\"\n",
    "    if len(points_2d) < 3: return None\n",
    "    hull = ConvexHull(points_2d)\n",
    "    hull_points = points_2d[hull.vertices]\n",
    "    min_area = float('inf')\n",
    "    best_box = None\n",
    "    for i in range(len(hull_points)):\n",
    "        p1, p2 = hull_points[i], hull_points[(i + 1) % len(hull_points)]\n",
    "        edge_vector = p2 - p1\n",
    "        edge_angle = np.arctan2(edge_vector[1], edge_vector[0])\n",
    "        c, s = np.cos(-edge_angle), np.sin(-edge_angle)\n",
    "        rotation = np.array([[c, -s], [s, c]])\n",
    "        rotated_points = hull_points @ rotation.T\n",
    "        min_x, max_x = np.min(rotated_points[:, 0]), np.max(rotated_points[:, 0])\n",
    "        min_y, max_y = np.min(rotated_points[:, 1]), np.max(rotated_points[:, 1])\n",
    "        area = (max_x - min_x) * (max_y - min_y)\n",
    "        if area < min_area:\n",
    "            min_area = area\n",
    "            corners_in_rotated_frame = np.array([\n",
    "                [min_x, min_y], [max_x, min_y], [max_x, max_y], [min_x, max_y]\n",
    "            ])\n",
    "            best_box = corners_in_rotated_frame @ rotation\n",
    "    return best_box\n",
    "\n",
    "def get_plane_bounding_corners(inlier_points_centered, plane_equation) -> Optional[np.ndarray]:\n",
    "    \"\"\"Calculates the 4 corners of the plane's tightest bounding rectangle.\"\"\"\n",
    "    print(\"\\n[Task] Calculating the 4 corners of the plane's bounding rectangle...\")\n",
    "    obb_center_centered = np.array(plane_equation.get('obb_center'))\n",
    "    point_on_plane, normal = plane_equation_to_point_normal(plane_equation['equation'], fallback_point=obb_center_centered)\n",
    "    axis_z = normal\n",
    "    arbitrary_vec = np.array([0,0,1])\n",
    "    if np.allclose(np.abs(np.dot(axis_z, arbitrary_vec)), 1.0): arbitrary_vec = np.array([0,1,0])\n",
    "    axis_x = np.cross(axis_z, arbitrary_vec); axis_x /= np.linalg.norm(axis_x)\n",
    "    axis_y = np.cross(axis_z, axis_x)\n",
    "    vectors_from_origin = inlier_points_centered - point_on_plane\n",
    "    points_2d = np.vstack([np.dot(vectors_from_origin, axis_x), np.dot(vectors_from_origin, axis_y)]).T\n",
    "    corners_2d = find_minimum_bounding_rectangle(points_2d)\n",
    "    if corners_2d is None:\n",
    "        print(\"   - ERROR: Could not compute 2D bounding box.\")\n",
    "        return None\n",
    "    corners_3d_centered = point_on_plane + corners_2d[:, 0, np.newaxis] * axis_x + corners_2d[:, 1, np.newaxis] * axis_y\n",
    "    print(\"   - Successfully calculated 4 corners in 3D (centered space).\")\n",
    "    return corners_3d_centered\n",
    "\n",
    "def create_texture_from_corner_distortion(rgb_image_path, corners_3d_world, corners_2d_pixels, output_path):\n",
    "    \"\"\"Creates a perspective-corrected texture based on corner distortion.\"\"\"\n",
    "    print(\"\\n[Task] Creating perspective-corrected texture from corner distortion...\")\n",
    "    try:\n",
    "        source_image = Image.open(rgb_image_path)\n",
    "        w, h = source_image.size\n",
    "    except Exception as e:\n",
    "        print(f\"   - ERROR: Could not load image. Error: {e}\")\n",
    "        return None, None\n",
    "    edge_3d_1, edge_3d_2 = np.linalg.norm(corners_3d_world[1] - corners_3d_world[0]), np.linalg.norm(corners_3d_world[3] - corners_3d_world[0])\n",
    "    edge_2d_1_vec, edge_2d_2_vec = corners_2d_pixels[1] - corners_2d_pixels[0], corners_2d_pixels[3] - corners_2d_pixels[0]\n",
    "    edge_2d_1, edge_2d_2 = np.linalg.norm(edge_2d_1_vec), np.linalg.norm(edge_2d_2_vec)\n",
    "    if abs(edge_2d_1_vec[0]) > abs(edge_2d_1_vec[1]):\n",
    "        h_edge_3d, v_edge_3d, h_edge_2d, v_edge_2d = edge_3d_1, edge_3d_2, edge_2d_1, edge_2d_2\n",
    "    else:\n",
    "        h_edge_3d, v_edge_3d, h_edge_2d, v_edge_2d = edge_3d_2, edge_3d_1, edge_2d_2, edge_2d_1\n",
    "    if h_edge_3d == 0 or v_edge_3d == 0: return None, None\n",
    "    density_h, density_v = h_edge_2d / h_edge_3d, v_edge_2d / v_edge_3d\n",
    "    if density_h == 0 or density_v == 0: return None, None\n",
    "    target_density = max(density_h, density_v)\n",
    "    scale_w, scale_h = target_density / density_h, target_density / density_v\n",
    "    new_w, new_h = int(w * scale_w), int(h * scale_h)\n",
    "    if new_w == 0 or new_h == 0: return None, None\n",
    "    print(f\"   - Final upscaled image size: {new_w}x{new_h}\")\n",
    "    upscaled_image = source_image.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
    "    upscaled_image.save(output_path)\n",
    "    print(f\"   - Saved upscaled texture to: {output_path}\")\n",
    "    return (new_w, new_h), (scale_w, scale_h)\n",
    "\n",
    "def project_inliers_onto_plane(inlier_points_centered, plane_equation) -> np.ndarray:\n",
    "    \"\"\"Projects the noisy inlier points onto the ideal mathematical plane.\"\"\"\n",
    "    print(\"\\n[Task] Projecting inlier points onto the ideal plane...\")\n",
    "    eq = np.array(plane_equation['equation'])\n",
    "    normal, d = eq[:3], eq[3]\n",
    "    distances = inlier_points_centered @ normal + d\n",
    "    projected_points_centered = inlier_points_centered - distances[:, np.newaxis] * normal\n",
    "    print(f\"   - Successfully projected {len(projected_points_centered)} points.\")\n",
    "    return projected_points_centered\n",
    "\n",
    "# Need some refinements here\n",
    "def create_distorted_texture(source_image_path, source_points, dest_points, output_path):\n",
    "    \"\"\"Warps an image based on a sparse vector field of moving points.\"\"\"\n",
    "    print(\"\\n[Task] Creating distorted texture using vector field warp...\")\n",
    "    try:\n",
    "        source_image = np.array(Image.open(source_image_path))\n",
    "        h, w, _ = source_image.shape\n",
    "    except Exception as e:\n",
    "        print(f\"   - ERROR: Could not load source upscaled image. Error: {e}\")\n",
    "        return\n",
    "    vectors = dest_points - source_points\n",
    "    grid_y, grid_x = np.mgrid[0:h, 0:w]\n",
    "    displacement_field = griddata(dest_points, vectors, (grid_x, grid_y), method='cubic', fill_value=0)\n",
    "    map_y = grid_y - displacement_field[:,:,1]\n",
    "    map_x = grid_x - displacement_field[:,:,0]\n",
    "    warped_image_r = map_coordinates(source_image[:,:,0], [map_y, map_x], order=1, mode='constant', cval=0)\n",
    "    warped_image_g = map_coordinates(source_image[:,:,1], [map_y, map_x], order=1, mode='constant', cval=0)\n",
    "    warped_image_b = map_coordinates(source_image[:,:,2], [map_y, map_x], order=1, mode='constant', cval=0)\n",
    "    distorted_image_np = np.stack([warped_image_r, warped_image_g, warped_image_b], axis=-1).astype(np.uint8)\n",
    "    distorted_image = Image.fromarray(distorted_image_np)\n",
    "    distorted_image.save(output_path)\n",
    "    print(f\"   - Saved distorted texture to: {output_path}\")\n",
    "\n",
    "# Revise this for a smoother mask, is the math the same resolution?\n",
    "def create_mask_on_texture(texture_path, scaled_points_2d, point_radius, output_mask_path):\n",
    "    \"\"\"Creates and saves a mask by drawing circles on a blank canvas.\"\"\"\n",
    "    print(\"\\n[Task] Creating mask for the upscaled texture...\")\n",
    "    try:\n",
    "        texture = Image.open(texture_path)\n",
    "        mask = Image.new('L', texture.size, 0)\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "        for p in scaled_points_2d:\n",
    "            bbox = (p[0] - point_radius, p[1] - point_radius, p[0] + point_radius, p[1] + point_radius)\n",
    "            draw.ellipse(bbox, fill=255)\n",
    "        mask.save(output_mask_path)\n",
    "        print(f\"   - Saved mask to: {output_mask_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   - ERROR: Could not create mask. Error: {e}\")\n",
    "\n",
    "def apply_mask_to_texture(distorted_path: str, mask_path: str, output_path: str, feather: float = 0.0):\n",
    "    \"\"\"\n",
    "    Keep only the masked pixels from `distorted_path`, make all others transparent,\n",
    "    and save a new PNG with alpha at `output_path`.\n",
    "    \"\"\"\n",
    "    img = Image.open(distorted_path).convert(\"RGBA\")\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "    if mask.size != img.size:\n",
    "        mask = mask.resize(img.size, resample=Image.BILINEAR)\n",
    "\n",
    "    if feather > 0:\n",
    "        mask = mask.filter(ImageFilter.GaussianBlur(radius=feather))\n",
    "\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "    mask_np = np.array(mask).astype(np.float32) / 255.0\n",
    "\n",
    "    # Premultiply RGB by mask\n",
    "    img_np[..., 0:3] *= mask_np[..., None]\n",
    "\n",
    "    # Set alpha = mask\n",
    "    img_np[..., 3] = mask_np * 255.0\n",
    "\n",
    "    out = Image.fromarray(img_np.astype(np.uint8), mode=\"RGBA\")\n",
    "    out.save(output_path)\n",
    "    print(f\"   - Saved masked texture to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e424872",
   "metadata": {},
   "source": [
    "## Rectify plane ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a4c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "# ---------- small helpers ----------\n",
    "\n",
    "def _homography_from_4pts(src_xy, dst_uv):\n",
    "    \"\"\"\n",
    "    DLT homography from 4 points.\n",
    "    src_xy: (4,2) -> rectangle or plane coords\n",
    "    dst_uv: (4,2) -> image pixel coords\n",
    "    Returns H s.t. [u v 1]^T ~ H [x y 1]^T\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    for (x, y), (u, v) in zip(src_xy, dst_uv):\n",
    "        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y, -u])\n",
    "        A.append([0, 0, 0, x, y, 1, -v*x, -v*y, -v])\n",
    "    A = np.asarray(A, dtype=np.float64)\n",
    "    _, _, Vt = np.linalg.svd(A)\n",
    "    h = Vt[-1] / Vt[-1, -1]\n",
    "    return h.reshape(3, 3)\n",
    "\n",
    "def _warp_rect_from_quad(image_np, quad_uv, W, H):\n",
    "    \"\"\"\n",
    "    Sample 'image_np' over a W x H rect by mapping each rect pixel\n",
    "    to the image quad via homography. Returns uint8 RGBA.\n",
    "    quad_uv: (4,2) pixel coords in order [C0, C1, C2, C3]\n",
    "    \"\"\"\n",
    "    rect_pts = np.array([[0, 0], [W-1, 0], [W-1, H-1], [0, H-1]], dtype=np.float64)\n",
    "    H_rect_to_img = _homography_from_4pts(rect_pts, quad_uv.astype(np.float64))\n",
    "\n",
    "    xs = np.linspace(0, W-1, W)\n",
    "    ys = np.linspace(0, H-1, H)\n",
    "    X, Y = np.meshgrid(xs, ys)\n",
    "    ones = np.ones_like(X)\n",
    "    XY1 = np.stack([X, Y, ones], axis=-1)             # (H, W, 3)\n",
    "    UVW = XY1 @ H_rect_to_img.T\n",
    "    U = UVW[..., 0] / (UVW[..., 2] + 1e-9)\n",
    "    V = UVW[..., 1] / (UVW[..., 2] + 1e-9)\n",
    "\n",
    "    out = np.zeros((H, W, image_np.shape[2]), dtype=np.float32)\n",
    "    for c in range(image_np.shape[2]):\n",
    "        out[..., c] = map_coordinates(image_np[..., c], [V, U],\n",
    "                                      order=1, mode='constant', cval=0.0)\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "# ---------- main 2-step function ----------\n",
    "\n",
    "def rectify_plane_texture_two_step(\n",
    "    masked_texture_path: str,\n",
    "    corners_pixels: np.ndarray,    # (4,2) pixel coords in the *same image space* as masked_texture\n",
    "    corners_3d_world: np.ndarray,  # (4,3) 3D corners in camera/world coords\n",
    "    output_path: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Step 1: crop quad -> rectangle using current UVs (pixel corners).\n",
    "    Step 2: remove foreshortening by rescaling to plane's metric aspect (Lx/Ly).\n",
    "    Output keeps highest reasonable detail (no downsampling along either axis).\n",
    "    Corner order must be [C0, C1, C2, C3] going around the quad\n",
    "    such that C0->C1 and C0->C3 are the two edges that meet at C0.\n",
    "    \"\"\"\n",
    "    # Load masked RGBA (already premultiplied in your pipeline)\n",
    "    img = Image.open(masked_texture_path).convert(\"RGBA\")\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "\n",
    "    # --- STEP 1: quad crop (choose rect size from *projected* edge lengths) ---\n",
    "    c0, c1, c2, c3 = [np.asarray(p, dtype=np.float64) for p in corners_pixels]\n",
    "    W1 = int(np.ceil(np.linalg.norm(c1 - c0)))\n",
    "    H1 = int(np.ceil(np.linalg.norm(c3 - c0)))\n",
    "    W1 = max(W1, 1); H1 = max(H1, 1)\n",
    "\n",
    "    step1_np = _warp_rect_from_quad(img_np, np.stack([c0, c1, c2, c3], axis=0), W1, H1)\n",
    "\n",
    "    # --- STEP 2: un-foreshorten to true plane aspect using 3D edge lengths ---\n",
    "    C0, C1, C2, C3 = [np.asarray(P, dtype=np.float64) for P in corners_3d_world]\n",
    "    Lx = float(np.linalg.norm(C1 - C0))   # metric width\n",
    "    Ly = float(np.linalg.norm(C3 - C0))   # metric height\n",
    "    if Lx <= 1e-12 or Ly <= 1e-12:\n",
    "        raise ValueError(\"Degenerate plane edges (zero length).\")\n",
    "\n",
    "    # Preserve detail: pick pixels-per-meter so we don't downsample either axis\n",
    "    s = max(W1 / Lx, H1 / Ly)\n",
    "    W_out = max(1, int(np.ceil(Lx * s)))\n",
    "    H_out = max(1, int(np.ceil(Ly * s)))\n",
    "\n",
    "    # Resample step1 to (W_out, H_out) with high-quality filter\n",
    "    step1_img = Image.fromarray(step1_np, mode=\"RGBA\")\n",
    "    step2_img = step1_img.resize((W_out, H_out), Image.Resampling.LANCZOS)\n",
    "    step2_img.save(output_path)\n",
    "    print(f\"âœ” Rectified plane texture saved: {output_path}  (size: {W_out}x{H_out})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_textured_planes(\n",
    "    vignette: \"ProcessedVignette\",\n",
    "    rgb_image_path: str,\n",
    "    output_dir: str,\n",
    "    point_radius: int = 10,\n",
    "    target_plane_id: int = -1 # -1 for all planes\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Main method that takes in a processed vignette, take its texture and plane abstraction.\n",
    "    Create a set of textured planes.\n",
    "    \"\"\"\n",
    "    # Clear previous textured planes\n",
    "    vignette.clear_abstractions('textured_planes', auto_save=False)\n",
    "\n",
    "    # Load necessary data\n",
    "    planes = vignette.get_abstractions('planes')\n",
    "    if not planes:\n",
    "        print(\"   - No planes found. Aborting.\")\n",
    "        return\n",
    "    capture_meta = vignette.metadata.get('capture_metadata', {})\n",
    "    center_offset = np.array(capture_meta.get('center_offset', [0, 0, 0]))\n",
    "    intrinsics = np.array(capture_meta.get('camera_intrinsics', {}).get('columns', np.identity(3))).T\n",
    "\n",
    "    try:\n",
    "        source_image = Image.open(rgb_image_path).convert(\"RGBA\")\n",
    "        w, h = source_image.size\n",
    "    except Exception as e:\n",
    "        print(f\"   - ERROR: Could not read source image at {rgb_image_path}. Error: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Prepare asset folder\n",
    "    assets_path = Path(output_dir) / \"assets\" / \"planes\"\n",
    "    assets_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    textured_planes_list: List[Dict[str, Any]] = []\n",
    "\n",
    "    # For each plane\n",
    "    for plane in planes:\n",
    "        plane_id = plane.get('plane_id')\n",
    "        if target_plane_id != -1 and target_plane_id != plane_id:\n",
    "            print(f\"\\n--- Skipping plane {plane_id} ---\")\n",
    "            continue\n",
    "        print(f\"\\n--- Processing plane {plane_id} ---\")\n",
    "\n",
    "        # get plane bounding corners \n",
    "        inlier_points_centered = vignette.points[plane['point_indices']] # Points on the plane\n",
    "        corners_3d_centered = get_plane_bounding_corners(inlier_points_centered, plane)\n",
    "        if corners_3d_centered is None: \n",
    "            print(\"   - Plane corneres not found. Aborting.\")\n",
    "            return\n",
    "        corners_3d_world = corners_3d_centered + center_offset\n",
    "        corners_2d_pixels = project_points_to_2d(corners_3d_world, intrinsics)\n",
    "\n",
    "        # Get a stretched texture to ensure pixel density\n",
    "        output_texture_path = assets_path / f\"plane_{plane_id}_perspective_corrected.png\"\n",
    "        new_dims, scale_factors = create_texture_from_corner_distortion(rgb_image_path, corners_3d_world, corners_2d_pixels, str(output_texture_path))\n",
    "        if not new_dims:\n",
    "            print(\"   - Error distorting plane. Aborting.\")\n",
    "            return\n",
    "        new_w, new_h = new_dims\n",
    "       \n",
    "        # Project all points onto the plane\n",
    "        projected_points_centered = project_inliers_onto_plane(inlier_points_centered, plane)\n",
    "\n",
    "        # Distort texture with point projection vectors\n",
    "        inlier_points_world = inlier_points_centered + center_offset\n",
    "        inlier_pixel_coords = project_points_to_2d(inlier_points_world, intrinsics)\n",
    "        scaled_inlier_coords = inlier_pixel_coords * np.array(scale_factors)\n",
    "\n",
    "        projected_points_world = projected_points_centered + center_offset\n",
    "        projected_pixel_coords = project_points_to_2d(projected_points_world, intrinsics)\n",
    "        scaled_projected_coords = projected_pixel_coords * np.array(scale_factors)\n",
    "\n",
    "        output_distorted_path = assets_path / f\"plane_{plane_id}_distorted.png\"\n",
    "        create_distorted_texture(str(output_texture_path), scaled_inlier_coords, scaled_projected_coords, str(output_distorted_path))\n",
    "\n",
    "        # Create a mask for this plane\n",
    "        output_mask_path = assets_path / f\"plane_{plane_id}_mask.png\"\n",
    "        create_mask_on_texture(str(output_distorted_path), scaled_projected_coords, point_radius=point_radius, output_mask_path=str(output_mask_path))\n",
    "\n",
    "        # Apply mask to distorted_texture\n",
    "        output_masked_texture_path = assets_path / f\"plane_{plane_id}_distorted_masked.png\"\n",
    "        apply_mask_to_texture(\n",
    "            distorted_path=str(output_distorted_path),\n",
    "            mask_path=str(output_mask_path),\n",
    "            output_path=str(output_masked_texture_path),\n",
    "            feather=0.5 * point_radius,   # optional: soften edges a bit\n",
    "        )\n",
    "\n",
    "        # Get a cropped texture without perspective foreshortening\n",
    "        output_rectified_path = assets_path / f\"plane_{plane_id}_rectified.png\"\n",
    "        scaled_corners_pixels = corners_2d_pixels * np.array(scale_factors)\n",
    "        rectify_plane_texture_two_step(\n",
    "            masked_texture_path=str(output_masked_texture_path),\n",
    "            corners_pixels=scaled_corners_pixels,   # (4,2) in the SAME image space as masked texture\n",
    "            corners_3d_world=corners_3d_world,      # (4,3)\n",
    "            output_path=str(output_rectified_path)\n",
    "        )\n",
    "\n",
    "        # Save results in the vignette\n",
    "        corner_uvs = corners_2d_pixels / np.array(source_image.size)\n",
    "        textured_planes_list.append({\n",
    "            \"plane_id\": plane_id,\n",
    "            \"corners_3d_centered\": corners_3d_centered.tolist(),\n",
    "            \"corner_uvs\": corner_uvs.tolist(),\n",
    "            \"mesh_faces\": [[0, 1, 3], [1, 2, 3]], # Quad faces\n",
    "            \"scale_factors\": {\n",
    "                \"w\": scale_factors[0],\n",
    "                \"h\": scale_factors[1]\n",
    "            },\n",
    "            \"asset_paths\": {\n",
    "                \"perspective_corrected\": str(output_texture_path.relative_to(output_texture_path.parent.parent.parent)),\n",
    "                \"distorted\": str(output_distorted_path.relative_to(output_distorted_path.parent.parent.parent)),\n",
    "                \"mask\": str(output_mask_path.relative_to(output_mask_path.parent.parent.parent)),\n",
    "                \"distorted_masked\": str(output_masked_texture_path.relative_to(output_masked_texture_path.parent.parent.parent)),\n",
    "                \"rectified\": str(output_rectified_path.relative_to(output_rectified_path.parent.parent.parent))\n",
    "            }\n",
    "        })\n",
    "        print(f\"   - Successfully saved analysis results for plane {plane_id}.\")\n",
    "\n",
    "    vignette.metadata['textured_abstractions'] = {'planes': textured_planes_list}\n",
    "    vignette.save()\n",
    "    print(\"\\n--- Finished Plane-Driven Textured Plane Creation ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e1dad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set/updated per-point attribute: 'confidence'.\n",
      "Set/updated per-point attribute: 'plane_id'.\n",
      "Set/updated per-point attribute: 'cylinder_id'.\n",
      "Set/updated per-point attribute: 'sphere_id'.\n",
      "Set/updated per-point attribute: 'cuboid_id'.\n",
      "Set/updated per-point attribute: 'component_id'.\n",
      "Set/updated per-point attribute: 'best_fit_id'.\n",
      "Loaded processed vignette from: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/results/processed_vignette.npz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_textured_planes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvignette_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProcessedVignette\n\u001b[32m      3\u001b[39m processed_vignette = ProcessedVignette.load(processed_vignette_path)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mcreate_textured_planes\u001b[49m(processed_vignette, rgb_path, VIGNETTE_PATH)\n",
      "\u001b[31mNameError\u001b[39m: name 'create_textured_planes' is not defined"
     ]
    }
   ],
   "source": [
    "processed_vignette_path = results_path / \"processed_vignette.npz\"\n",
    "from pipeline.vignette_data import ProcessedVignette\n",
    "processed_vignette = ProcessedVignette.load(processed_vignette_path)\n",
    "create_textured_planes(processed_vignette, rgb_path, VIGNETTE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b97cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d.visualization import rendering\n",
    "\n",
    "# Visualize them\n",
    "def visualize_planes(vignette: \"ProcessedVignette\", show_points: bool = True, target_plane_id: int = -1):\n",
    "    textured_planes = vignette.metadata.get('textured_abstractions', {}).get('planes', [])\n",
    "    if not textured_planes:\n",
    "        print(\"  - No textured plane found. Aborting.\")\n",
    "        return\n",
    "    \n",
    "    geometries_to_draw = []\n",
    "\n",
    "    # Points\n",
    "    if show_points:\n",
    "        pcd = processed_vignette.to_open3d()\n",
    "        colors_np = np.asarray(pcd.colors)\n",
    "        \n",
    "        if target_plane_id != -1:\n",
    "            # Color points for the plane\n",
    "            abs_plane = next((p for p in processed_vignette.get_abstractions('planes') if p.get('plane_id') == target_plane_id), None)\n",
    "            if abs_plane and abs_plane.get('point_indices'):\n",
    "                idx = np.asarray(abs_plane['point_indices'], dtype=int)\n",
    "                idx = idx[(idx >= 0) & (idx < colors_np.shape[0])]\n",
    "                colors_np[idx] = [1.0, 0.0, 0.0] # Red\n",
    "        \n",
    "        # colors_np = np.zeros((colors_np.shape[0], 3), dtype=float)\n",
    "\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors_np)\n",
    "        pcd_mat = rendering.MaterialRecord()\n",
    "        pcd_mat.shader = \"defaultUnlit\"\n",
    "\n",
    "        geometries_to_draw.append({\"name\": \"point_cloud\", \"geometry\": pcd, \"material\": pcd_mat})\n",
    "        print(\"--- Visualized Points ---\")\n",
    "\n",
    "    # Planes\n",
    "    for plane in textured_planes:\n",
    "        plane_id = plane.get('plane_id')\n",
    "        if target_plane_id != -1 and target_plane_id != plane_id:\n",
    "            print(f\"--- Skipping plane {plane_id} ---\")\n",
    "            continue\n",
    "\n",
    "        print(f\"--- Preparing plane {plane_id} ---\")\n",
    "        # Get geometry\n",
    "        vertices_np = np.asarray(plane['corners_3d_centered'])\n",
    "        #faces_ij_k = plane['mesh_faces']\n",
    "\n",
    "        front_faces = [list(map(int, f)) for f in plane['mesh_faces']]  # [[i,j,k], ...]\n",
    "        # back_faces  = [[tri[0], tri[2], tri[1]] for tri in front_faces]        # reverse winding for back\n",
    "        all_faces   = front_faces # + back_faces\n",
    "        # plane_mesh, all_faces = build_double_sided_mesh(vertices_np, faces_ij_k)\n",
    "        plane_mesh = o3d.geometry.TriangleMesh(\n",
    "            o3d.utility.Vector3dVector(vertices_np),\n",
    "            o3d.utility.Vector3iVector(all_faces),\n",
    "        )\n",
    "\n",
    "        # Add UVs\n",
    "        # Use 0-1 instead\n",
    "        # per_vertex_uv = np.asarray(plane['corner_uvs'], dtype=float)\n",
    "        per_vertex_uv = np.array([\n",
    "            [0.0, 0.0],  # corner 0\n",
    "            [1.0, 0.0],  # corner 1\n",
    "            [1.0, 1.0],  # corner 2\n",
    "            [0.0, 1.0],  # corner 3\n",
    "        ], dtype=float)\n",
    "        per_vertex_uv[:, 1] = 1.0 - per_vertex_uv[:, 1] # flip v\n",
    "\n",
    "        tri_uv_list = []\n",
    "        for (i, j, k) in all_faces:\n",
    "            tri_uv_list.extend([per_vertex_uv[i], per_vertex_uv[j], per_vertex_uv[k]])\n",
    "        tri_uvs = np.asarray(tri_uv_list, dtype=float)  # shape: (num_triangles*3, 2)\n",
    "\n",
    "        plane_mesh.triangle_uvs = o3d.utility.Vector2dVector(tri_uvs)\n",
    "        plane_mesh.compute_vertex_normals()\n",
    "\n",
    "        # Transparent material (default)\n",
    "        tex_path = (VIGNETTE_PATH / plane['asset_paths']['rectified']).resolve()\n",
    "        # tex_path = (VIGNETTE_PATH / 'rgb.png').resolve()\n",
    "        mat = rendering.MaterialRecord()\n",
    "        mat.shader = \"defaultLitTransparency\"\n",
    "        mat.albedo_img = o3d.io.read_image(str(tex_path))\n",
    "\n",
    "        geometries_to_draw.append({\n",
    "            \"name\": f\"plane_{plane_id}\",\n",
    "            \"geometry\": plane_mesh,\n",
    "            \"material\": mat\n",
    "        })\n",
    "\n",
    "        print(f\"  - Plane {plane_id} Ready\")\n",
    "\n",
    "    o3d.visualization.draw(\n",
    "        geometries_to_draw,\n",
    "        show_skybox = False,\n",
    "        bg_color=(1, 1, 1, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f4920e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Open3D point cloud with 'rgb' colors...\n",
      "--- Visualized Points ---\n",
      "--- Preparing plane 1 ---\n",
      "  - Plane 1 Ready\n",
      "--- Preparing plane 2 ---\n",
      "  - Plane 2 Ready\n",
      "--- Preparing plane 3 ---\n",
      "  - Plane 3 Ready\n",
      "--- Preparing plane 4 ---\n",
      "  - Plane 4 Ready\n",
      "--- Preparing plane 5 ---\n",
      "  - Plane 5 Ready\n",
      "--- Preparing plane 6 ---\n",
      "  - Plane 6 Ready\n",
      "--- Preparing plane 7 ---\n",
      "  - Plane 7 Ready\n"
     ]
    }
   ],
   "source": [
    "visualize_planes(processed_vignette, target_plane_id=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f303c1",
   "metadata": {},
   "source": [
    "### Debug UVs ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77759385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 textured planes. Writing UV debug overlays...\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_1_mask_plane1_UV-topLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_1_mask_plane1_UV-bottomLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_2_mask_plane2_UV-topLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_2_mask_plane2_UV-bottomLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_3_mask_plane3_UV-topLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_3_mask_plane3_UV-bottomLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_4_mask_plane4_UV-topLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_4_mask_plane4_UV-bottomLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_5_mask_plane5_UV-topLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_5_mask_plane5_UV-bottomLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_6_mask_plane6_UV-topLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_6_mask_plane6_UV-bottomLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_7_mask_plane7_UV-topLeft.png\n",
      "[UV DEBUG] Saved: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs/plane_7_mask_plane7_UV-bottomLeft.png\n",
      "\n",
      "Done. Planes processed: 7 | Saved: 7 | Skipped: 0\n",
      "Check your UV overlays in: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/debug_uvs\n"
     ]
    }
   ],
   "source": [
    "# --- UV Debug Saver (no rendering; all planes) --------------------------------\n",
    "# Assumes these exist in your notebook:\n",
    "#   VIGNETTE_PATH: pathlib.Path to your vignette folder\n",
    "#   processed_vignette: your loaded ProcessedVignette instance\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# =========================\n",
    "# Helpers for UV debugging\n",
    "# =========================\n",
    "def _draw_cross(draw: ImageDraw.ImageDraw, xy, size=8, width=2):\n",
    "    x, y = xy\n",
    "    draw.line((x - size, y, x + size, y), width=width)\n",
    "    draw.line((x, y - size, x, y + size), width=width)\n",
    "\n",
    "def _uv_to_px_top_left(u, v, W, H):\n",
    "    # (0,0) at top-left; v increases downward (image-space)\n",
    "    return (u * (W - 1), v * (H - 1))\n",
    "\n",
    "def _uv_to_px_bottom_left(u, v, W, H):\n",
    "    # (0,0) at bottom-left; v increases upward (GL-style)\n",
    "    return (u * (W - 1), (1.0 - v) * (H - 1))\n",
    "\n",
    "def save_uv_debug_images(texture_path: Path, uv_corners, out_dir: Path, plane_id: int):\n",
    "    \"\"\"\n",
    "    Draw the 4 UV corner points over the texture and save two PNGs:\n",
    "      - *_UV-topLeft.png     (assumes v downward)\n",
    "      - *_UV-bottomLeft.png  (assumes v upward)\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    img = Image.open(texture_path).convert(\"RGBA\")\n",
    "    W, H = img.size\n",
    "\n",
    "    canvases = [\n",
    "        (\"topLeft\", _uv_to_px_top_left),\n",
    "        (\"bottomLeft\", _uv_to_px_top_left),\n",
    "    ]\n",
    "\n",
    "    stroke = 3\n",
    "    try:\n",
    "        font = ImageFont.load_default()\n",
    "    except Exception:\n",
    "        font = None\n",
    "\n",
    "    uv_corners = np.asarray(uv_corners, dtype=float).reshape(4, 2)\n",
    "\n",
    "    for label, uv2px in canvases:\n",
    "        canvas = img.copy()\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "        # Convert each UV to pixel coordinates\n",
    "        px = [uv2px(float(u), float(v), W, H) for (u, v) in uv_corners]\n",
    "\n",
    "        # Connect corners (0->1->2->3->0) and draw crosshairs + labels\n",
    "        draw.line([*px, px[0]], width=stroke)\n",
    "        for i, (x, y) in enumerate(px):\n",
    "            _draw_cross(draw, (x, y), size=8, width=stroke)\n",
    "            draw.text((x + 6, y + 6), f\"{i} ({uv_corners[i,0]:.3f},{uv_corners[i,1]:.3f})\", font=font)\n",
    "\n",
    "        out_path = out_dir / f\"{texture_path.stem}_plane{plane_id}_UV-{label}.png\"\n",
    "        canvas.save(out_path)\n",
    "        print(f\"[UV DEBUG] Saved: {out_path}\")\n",
    "\n",
    "# ==================================\n",
    "# Gather planes and write UV overlays\n",
    "# ==================================\n",
    "textured_abstractions = processed_vignette.metadata.get('textured_abstractions', {}).get('planes', [])\n",
    "uv_debug_dir = (VIGNETTE_PATH / \"debug_uvs\").resolve()\n",
    "\n",
    "if not textured_abstractions:\n",
    "    print(\"No textured planes found to debug.\")\n",
    "else:\n",
    "    print(f\"Found {len(textured_abstractions)} textured planes. Writing UV debug overlays...\")\n",
    "    saved_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for plane_data in textured_abstractions:\n",
    "        plane_id = plane_data.get('plane_id', 'unknown')\n",
    "        # Expecting plane_data['mesh_uvs'] to be 4 corners in [0,1]\n",
    "        uv_corners = plane_data.get('corner_uvs', None)\n",
    "        asset_paths = plane_data.get('asset_paths', None)\n",
    "        rel_tex = asset_paths.get('mask', None)\n",
    "\n",
    "        if uv_corners is None or rel_tex is None:\n",
    "            print(f\"[SKIP] Plane {plane_id}: missing mesh_uvs or texture_path.\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        tex_path = (VIGNETTE_PATH / rel_tex).resolve()\n",
    "        if not tex_path.exists():\n",
    "            print(f\"[SKIP] Plane {plane_id}: texture not found at {tex_path}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            save_uv_debug_images(\n",
    "                texture_path=tex_path,\n",
    "                uv_corners=np.asarray(uv_corners, dtype=float),\n",
    "                out_dir=uv_debug_dir,\n",
    "                plane_id=plane_id\n",
    "            )\n",
    "            saved_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Plane {plane_id}: failed to save UV debug: {e}\")\n",
    "            skipped_count += 1\n",
    "\n",
    "    print(f\"\\nDone. Planes processed: {len(textured_abstractions)} | Saved: {saved_count} | Skipped: {skipped_count}\")\n",
    "    print(\"Check your UV overlays in:\", uv_debug_dir)\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a3a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb1b84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set/updated per-point attribute: 'confidence'.\n",
      "Set/updated per-point attribute: 'plane_id'.\n",
      "Set/updated per-point attribute: 'cylinder_id'.\n",
      "Set/updated per-point attribute: 'sphere_id'.\n",
      "Set/updated per-point attribute: 'cuboid_id'.\n",
      "Set/updated per-point attribute: 'component_id'.\n",
      "Set/updated per-point attribute: 'best_fit_id'.\n",
      "Set/updated per-point attribute: 'curvature'.\n",
      "Set/updated per-point attribute: 'edgeness'.\n",
      "Set/updated per-point attribute: 'anisotropy'.\n",
      "Set/updated per-point attribute: 'planarity'.\n",
      "Set/updated per-point attribute: 'sphericity'.\n",
      "Set/updated per-point attribute: 'flow_vectors'.\n",
      "Loaded processed vignette from: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/results/processed_vignette.npz\n"
     ]
    }
   ],
   "source": [
    "processed_vignette_path = results_path / \"processed_vignette.npz\"\n",
    "from pipeline.vignette_data import ProcessedVignette\n",
    "processed_vignette = ProcessedVignette.load(processed_vignette_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26b30f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying components with eps=0.03...\n",
      "Set/updated per-point attribute: 'component_id'.\n",
      "   - Found 2 components and assigned 'component_id' attribute.\n",
      "Analyzing structural properties with PCA...\n",
      "Cleared 4 abstractions of type 'structural_properties'.\n",
      "Added new abstraction of type 'structural_properties'.\n",
      "   - Global properties: L=0.64, P=0.28, S=0.08\n",
      "   - Analyzing 2 components...\n",
      "     - Component #0: L=0.90, P=0.08, S=0.01\n",
      "Added new abstraction of type 'structural_properties'.\n",
      "     - Component #1: L=0.64, P=0.20, S=0.16\n",
      "Added new abstraction of type 'structural_properties'.\n",
      "Saved processed vignette to: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/results/processed_vignette.npz\n",
      "Finished structural property analysis.\n"
     ]
    }
   ],
   "source": [
    "# Test PCA\n",
    "from pipeline import abstraction\n",
    "# Identify Components\n",
    "abstraction.identify_components(\n",
    "    processed_vignette, \n",
    "    cluster_eps=0.03, # Neighborhood radius\n",
    "    min_cluster_points=100\n",
    ")\n",
    "\n",
    "# PCA Structural Analysis\n",
    "abstraction.analyze_structural_properties(processed_vignette, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2896578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Assuming your ProcessedVignette class is available\n",
    "# from vignette import ProcessedVignette \n",
    "\n",
    "def create_axis_visual(\n",
    "    properties: Dict[str, Any], \n",
    "    scale_factor: float = 1.0\n",
    ") -> o3d.geometry.LineSet:\n",
    "    \"\"\"\n",
    "    Creates an Open3D LineSet to represent the PCA axes.\n",
    "\n",
    "    Args:\n",
    "        properties: A dictionary containing 'centroid', 'axes', and 'variances'.\n",
    "        scale_factor: A multiplier to adjust the visual length of the axes.\n",
    "\n",
    "    Returns:\n",
    "        An o3d.geometry.LineSet object representing the three axes.\n",
    "    \"\"\"\n",
    "    center = np.array(properties['centroid'])\n",
    "    # axes is a list of 3 lists, each being a vector\n",
    "    axes = np.array(properties['axes']) \n",
    "    # variances is a list of 3 floats\n",
    "    variances = np.array(properties['variances'])\n",
    "\n",
    "    # The length of each axis line will be proportional to the standard deviation\n",
    "    # We use [:, np.newaxis] to properly broadcast the multiplication\n",
    "    axis_lengths = np.sqrt(variances) * scale_factor\n",
    "    endpoints = center + axes * axis_lengths[:, np.newaxis]\n",
    "\n",
    "    # The points for our LineSet: the center, then the 3 endpoints\n",
    "    points = np.vstack([center, endpoints])\n",
    "    \n",
    "    # The lines connect the center (index 0) to each endpoint (indices 1, 2, 3)\n",
    "    lines = [[0, 1], [0, 2], [0, 3]]\n",
    "    \n",
    "    # Colors for the axes: Red (primary), Green (secondary), Blue (tertiary)\n",
    "    # The order of pca.components_ is already from largest to smallest variance.\n",
    "    colors = [[1, 0, 0], [0, 1, 0], [0, 0, 1]] \n",
    "\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    return line_set\n",
    "\n",
    "\n",
    "def visualize_vignette_abstractions(\n",
    "    vignette: 'ProcessedVignette',\n",
    "    draw_global_props: bool = True,\n",
    "    draw_component_props: bool = True,\n",
    "    axis_scale_factor: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an interactive Open3D visualization of a vignette and its abstractions.\n",
    "\n",
    "    - Colors the point cloud by 'component_id'.\n",
    "    - Draws the principal axes for the global shape and/or individual components.\n",
    "\n",
    "    Args:\n",
    "        vignette: The ProcessedVignette object to visualize.\n",
    "        draw_global_props: If True, draws the PCA axes for the entire vignette.\n",
    "        draw_component_props: If True, draws the PCA axes for each component.\n",
    "        axis_scale_factor: Adjusts the visual length of the drawn axes.\n",
    "    \"\"\"\n",
    "    # 1. Generate the point cloud colored by component ID\n",
    "    try:\n",
    "        pcd = vignette.to_open3d(color_mode='component_id')\n",
    "    except AttributeError:\n",
    "        print(\"Warning: 'component_id' not found. Displaying with RGB colors.\")\n",
    "        pcd = vignette.to_open3d(color_mode='rgb')\n",
    "\n",
    "    geometries_to_draw = [pcd]\n",
    "    \n",
    "    # 2. Get the structural properties\n",
    "    all_props = vignette.get_abstractions('structural_properties')\n",
    "    if not all_props:\n",
    "        print(\"No structural properties found to visualize.\")\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "        return\n",
    "\n",
    "    # 3. Create geometries for the properties\n",
    "    for props in all_props:\n",
    "        if props['type'] == 'global' and draw_global_props:\n",
    "            print(\"Visualizing global properties...\")\n",
    "            global_axes = create_axis_visual(props, scale_factor=axis_scale_factor)\n",
    "            geometries_to_draw.append(global_axes)\n",
    "            \n",
    "        elif props['type'] == 'component' and draw_component_props:\n",
    "            comp_id = props['component_id']\n",
    "            print(f\"Visualizing properties for component #{comp_id}...\")\n",
    "            component_axes = create_axis_visual(props, scale_factor=axis_scale_factor)\n",
    "            geometries_to_draw.append(component_axes)\n",
    "            \n",
    "    # 4. Launch the visualizer\n",
    "    print(\"\\nLaunching Open3D visualizer...\")\n",
    "    print(\" - Press 'q' or 'esc' to close the window.\")\n",
    "    o3d.visualization.draw_geometries(geometries_to_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747e069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Open3D point cloud with 'component_id' colors...\n",
      "Visualizing global properties...\n",
      "Visualizing properties for component #0...\n",
      "Visualizing properties for component #1...\n",
      "\n",
      "Launching Open3D visualizer...\n",
      " - Press 'q' or 'esc' to close the window.\n"
     ]
    }
   ],
   "source": [
    "visualize_vignette_abstractions(\n",
    "    processed_vignette,\n",
    "    draw_global_props=True,    # Show axes for the whole object\n",
    "    draw_component_props=True, # Show axes for each colored part\n",
    "    axis_scale_factor=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050057d",
   "metadata": {},
   "source": [
    "## Symmetry ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78727c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "# (Keep your _reflect_points helper function as is)\n",
    "def _reflect_points(points, plane_normal, plane_point):\n",
    "    normal = np.array(plane_normal) / np.linalg.norm(plane_normal)\n",
    "    d = -np.dot(normal, np.array(plane_point))\n",
    "    dists = np.dot(points, normal) + d\n",
    "    return points - 2 * dists[:, np.newaxis] * normal\n",
    "\n",
    "\n",
    "def _score_reflection_plane_robust(points, point_tree, plane_normal, plane_point, match_threshold):\n",
    "    \"\"\"Robustly scores a reflection plane using bidirectional consistency.\"\"\"\n",
    "    # Forward check\n",
    "    reflected_points = _reflect_points(points, plane_normal, plane_point)\n",
    "    distances, neighbor_indices = point_tree.query(reflected_points, k=1)\n",
    "    \n",
    "    potential_inlier_mask = distances < match_threshold\n",
    "    potential_indices = np.where(potential_inlier_mask)[0]\n",
    "    \n",
    "    # --- [DEBUG] Print results of the initial forward check ---\n",
    "    print(f\"      [DEBUG] Potential inliers found (distance < {match_threshold}m): {len(potential_indices)} / {len(points)}\")\n",
    "\n",
    "    # Backward consistency check\n",
    "    consistent_inlier_indices = []\n",
    "    if len(potential_indices) > 0:\n",
    "        neighbors_to_check = points[neighbor_indices[potential_indices]]\n",
    "        reflected_neighbors = _reflect_points(neighbors_to_check, plane_normal, plane_point)\n",
    "        _, reverse_neighbor_indices = point_tree.query(reflected_neighbors, k=1)\n",
    "        \n",
    "        is_consistent = (reverse_neighbor_indices == potential_indices)\n",
    "        consistent_inlier_indices = potential_indices[is_consistent]\n",
    "        # --- [DEBUG] Print results of the backward consistency check ---\n",
    "        print(f\"      [DEBUG] Consistent inliers found (passed backward check): {len(consistent_inlier_indices)} / {len(potential_indices)}\")\n",
    "\n",
    "    if len(consistent_inlier_indices) == 0:\n",
    "        return {'score': float('inf'), 'inlier_ratio': 0, 'mean_error': float('inf')}\n",
    "        \n",
    "    inlier_ratio = len(consistent_inlier_indices) / len(points)\n",
    "    mean_error = np.mean(distances[consistent_inlier_indices])\n",
    "    score = mean_error / inlier_ratio if inlier_ratio > 0 else float('inf')\n",
    "    \n",
    "    return {'score': score, 'inlier_ratio': inlier_ratio, 'mean_error': mean_error}\n",
    "\n",
    "\n",
    "def analyze_global_symmetry(\n",
    "    vignette: 'ProcessedVignette', \n",
    "    match_threshold: float = 0.02, \n",
    "    min_inlier_ratio: float = 0.5,\n",
    "    auto_save: bool = False\n",
    ") -> None:\n",
    "    print(\"Analyzing global symmetry (robust method)...\")\n",
    "    vignette.clear_abstractions('symmetries', auto_save=False)\n",
    "\n",
    "    all_props = vignette.get_abstractions('structural_properties')\n",
    "    if not all_props:\n",
    "        print(\"   [DEBUG] EXIT: Structural properties not found. Run PCA first.\")\n",
    "        return\n",
    "    global_props = next((p for p in all_props if p['type'] == 'global'), None)\n",
    "    if not global_props:\n",
    "        print(\"   [DEBUG] EXIT: Global structural properties not found.\")\n",
    "        return\n",
    "\n",
    "    points = vignette.points\n",
    "    component_labels = vignette.get_attribute('component_id')\n",
    "    print(f\"   [DEBUG] Initial point count: {len(points)}\")\n",
    "    if component_labels is not None:\n",
    "        non_noise_mask = component_labels != -1\n",
    "        points = points[non_noise_mask]\n",
    "        print(f\"   [DEBUG] Non-noise point count: {len(points)}\")\n",
    "\n",
    "    if len(points) < 100:\n",
    "        print(f\"   [DEBUG] EXIT: Not enough points for reliable analysis (found {len(points)}, need 100).\")\n",
    "        return\n",
    "\n",
    "    point_tree = KDTree(points)\n",
    "    centroid = np.array(global_props['centroid'])\n",
    "    axes = np.array(global_props['axes'])\n",
    "\n",
    "    best_reflection = {'score': float('inf')}\n",
    "    axis_names = ['Primary', 'Secondary', 'Tertiary']\n",
    "\n",
    "    print(\"   --- Testing Reflectional Symmetry ---\")\n",
    "    for i in range(3):\n",
    "        plane_normal = axes[i]\n",
    "        print(f\"   -> Testing plane normal to '{axis_names[i]}' axis...\")\n",
    "        result = _score_reflection_plane_robust(points, point_tree, plane_normal, centroid, match_threshold)\n",
    "        print(f\"      [DEBUG] Result: Score={result['score']:.4f}, Inlier Ratio={result['inlier_ratio']:.2%}, Mean Error={result['mean_error']:.4f}m\")\n",
    "        \n",
    "        if result['score'] < best_reflection['score']:\n",
    "            best_reflection = result\n",
    "            best_reflection['plane_normal'] = plane_normal.tolist()\n",
    "\n",
    "    print(\"   --- Final Decision ---\")\n",
    "    best_inlier_ratio = best_reflection.get('inlier_ratio', 0)\n",
    "    print(f\"   [DEBUG] Best inlier ratio found: {best_inlier_ratio:.2%}. Required minimum: {min_inlier_ratio:.2%}\")\n",
    "    \n",
    "    if best_inlier_ratio > min_inlier_ratio:\n",
    "        print(f\"   SUCCESS: Found reflectional symmetry that meets the criteria!\")\n",
    "        reflection_result = {\n",
    "            'type': 'reflectional',\n",
    "            'score': best_reflection['score'],\n",
    "            'inlier_ratio': best_reflection['inlier_ratio'],\n",
    "            'mean_inlier_error': best_reflection['mean_error'],\n",
    "            'plane_point': centroid.tolist(),\n",
    "            'plane_normal': best_reflection['plane_normal']\n",
    "        }\n",
    "        vignette.add_abstraction('symmetries', reflection_result, auto_save=False)\n",
    "    else:\n",
    "        print(\"   - No reflectional symmetry found that passed the minimum inlier ratio threshold.\")\n",
    "\n",
    "    # (Rotational symmetry part would go here)\n",
    "    \n",
    "    print(\"Finished symmetry analysis.\")\n",
    "    if auto_save and vignette.file_path:\n",
    "        vignette.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5689bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing global symmetry (robust method)...\n",
      "   [DEBUG] Initial point count: 8971\n",
      "   [DEBUG] Non-noise point count: 8971\n",
      "   --- Testing Reflectional Symmetry ---\n",
      "   -> Testing plane normal to 'Primary' axis...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 3057 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 267 / 3057\n",
      "      [DEBUG] Result: Score=0.0489, Inlier Ratio=2.98%, Mean Error=0.0015m\n",
      "   -> Testing plane normal to 'Secondary' axis...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 8688 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 816 / 8688\n",
      "      [DEBUG] Result: Score=0.0173, Inlier Ratio=9.10%, Mean Error=0.0016m\n",
      "   -> Testing plane normal to 'Tertiary' axis...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 8647 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 1801 / 8647\n",
      "      [DEBUG] Result: Score=0.0071, Inlier Ratio=20.08%, Mean Error=0.0014m\n",
      "   --- Final Decision ---\n",
      "   [DEBUG] Best inlier ratio found: 20.08%. Required minimum: 50.00%\n",
      "   - No reflectional symmetry found that passed the minimum inlier ratio threshold.\n",
      "Finished symmetry analysis.\n"
     ]
    }
   ],
   "source": [
    "analyze_global_symmetry(\n",
    "    vignette=processed_vignette, \n",
    "    match_threshold=0.03, \n",
    "    min_inlier_ratio=0.5,\n",
    "    auto_save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a543fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex version\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import Dict, Any, Optional, List\n",
    "\n",
    "# (Keep _reflect_points and _score_reflection_plane_robust as they are)\n",
    "# ...\n",
    "\n",
    "def find_candidate_normals_via_voting(\n",
    "    points: np.ndarray, \n",
    "    num_samples: int = 500,\n",
    "    num_bins: int = 50\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Finds candidate symmetry plane normals using a pairwise voting scheme.\n",
    "\n",
    "    Args:\n",
    "        points: Centered point cloud (non-noise points).\n",
    "        num_samples: The number of random points to sample for generating pairs.\n",
    "        num_bins: The resolution of the voting space for spherical coordinates.\n",
    "\n",
    "    Returns:\n",
    "        A list of promising normal vectors.\n",
    "    \"\"\"\n",
    "    print(\"      [DEBUG] Starting pairwise voting to find more candidate planes...\")\n",
    "    # A KDTree on the centered points to find partners\n",
    "    tree = KDTree(points)\n",
    "    \n",
    "    # Accumulator for votes (azimuth, elevation)\n",
    "    accumulator = np.zeros((num_bins, num_bins))\n",
    "\n",
    "    # Sample a subset of points to generate pairs from\n",
    "    sample_indices = np.random.choice(len(points), size=min(num_samples, len(points)), replace=False)\n",
    "    \n",
    "    for i in sample_indices:\n",
    "        p_i = points[i]\n",
    "        # Search for a partner in the opposite direction\n",
    "        # We query for a few neighbors in the opposite direction to get a good candidate\n",
    "        _, partner_indices = tree.query(-p_i, k=5)\n",
    "        \n",
    "        for j in partner_indices:\n",
    "            if i == j: continue\n",
    "            p_j = points[j]\n",
    "            \n",
    "            # The normal of the perpendicular bisector is simply the vector connecting the pair\n",
    "            normal = p_j - p_i\n",
    "            norm_mag = np.linalg.norm(normal)\n",
    "            if norm_mag < 1e-6: continue\n",
    "            normal /= norm_mag\n",
    "            \n",
    "            # Convert normal vector to spherical coordinates (azimuth, elevation) for voting\n",
    "            # Azimuth (phi) -> [0, 2*pi], Elevation (theta) -> [0, pi]\n",
    "            phi = np.arctan2(normal[1], normal[0]) + np.pi # range [0, 2pi]\n",
    "            theta = np.arccos(normal[2]) # range [0, pi]\n",
    "            \n",
    "            # Map to bin indices\n",
    "            phi_idx = int((phi / (2 * np.pi)) * (num_bins - 1))\n",
    "            theta_idx = int((theta / np.pi) * (num_bins - 1))\n",
    "            \n",
    "            accumulator[theta_idx, phi_idx] += 1\n",
    "            \n",
    "    # Find the peak in the accumulator\n",
    "    # For more robustness, one could use peak-finding algorithms, but max is a good start.\n",
    "    # We will find the top 3 peaks for more candidates.\n",
    "    flat_indices = np.argsort(accumulator.flatten())[-3:] # Get top 3\n",
    "    \n",
    "    candidate_normals = []\n",
    "    print(f\"      [DEBUG] Top accumulator votes: {[accumulator.flatten()[i] for i in flat_indices]}\")\n",
    "    for flat_idx in flat_indices:\n",
    "        theta_idx, phi_idx = np.unravel_index(flat_idx, (num_bins, num_bins))\n",
    "        \n",
    "        # Convert bin index back to spherical coordinates\n",
    "        phi = (phi_idx / (num_bins - 1)) * 2 * np.pi - np.pi\n",
    "        theta = (theta_idx / (num_bins - 1)) * np.pi\n",
    "        \n",
    "        # Convert back to Cartesian normal vector\n",
    "        nx = np.cos(phi) * np.sin(theta)\n",
    "        ny = np.sin(phi) * np.sin(theta)\n",
    "        nz = np.cos(theta)\n",
    "        candidate_normals.append(np.array([nx, ny, nz]))\n",
    "        \n",
    "    return candidate_normals\n",
    "\n",
    "def analyze_global_symmetry(\n",
    "    vignette: 'ProcessedVignette', \n",
    "    match_threshold: float = 0.02, \n",
    "    min_inlier_ratio: float = 0.5,\n",
    "    use_voting: bool = True,\n",
    "    auto_save: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Analyzes global symmetry with a robust method for partial point clouds.\n",
    "    Combines PCA and pairwise voting to find candidate planes.\n",
    "    \"\"\"\n",
    "    print(\"Analyzing global symmetry (robust method)...\")\n",
    "    vignette.clear_abstractions('symmetries', auto_save=False)\n",
    "\n",
    "    # --- REORGANIZED & FIXED: Data Preparation and Sanity Checks ---\n",
    "    # 1. Check for and retrieve PCA results (structural properties).\n",
    "    all_props = vignette.get_abstractions('structural_properties')\n",
    "    if not all_props:\n",
    "        print(\"   [DEBUG] EXIT: Structural properties not found. Run PCA first.\")\n",
    "        return\n",
    "        \n",
    "    global_props = next((p for p in all_props if p['type'] == 'global'), None)\n",
    "    if not global_props:\n",
    "        print(\"   [DEBUG] EXIT: Global structural properties not found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Prepare the point cloud, filtering out noise.\n",
    "    points = vignette.points\n",
    "    component_labels = vignette.get_attribute('component_id')\n",
    "    print(f\"   [DEBUG] Initial point count: {len(points)}\")\n",
    "    if component_labels is not None:\n",
    "        non_noise_mask = component_labels != -1\n",
    "        points = points[non_noise_mask]\n",
    "        print(f\"   [DEBUG] Non-noise point count: {len(points)}\")\n",
    "\n",
    "    if len(points) < 100:\n",
    "        print(f\"   [DEBUG] EXIT: Not enough points for reliable analysis (found {len(points)}, need 100).\")\n",
    "        return\n",
    "\n",
    "    # 3. Now that all checks have passed, define key variables.\n",
    "    # The centroid from PCA is our reference point for the plane's position.\n",
    "    centroid = np.array(global_props['centroid'])\n",
    "    # The point cloud centered around this specific centroid is used for voting.\n",
    "    centered_points = points - centroid\n",
    "    # The KDTree for scoring uses the original (non-centered) coordinates.\n",
    "    point_tree = KDTree(points)\n",
    "    \n",
    "    # --- Candidate Generation ---\n",
    "    candidate_normals = []\n",
    "    # Tier 1: Add the high-confidence PCA axes.\n",
    "    pca_axes = np.array(global_props['axes'])\n",
    "    candidate_normals.extend(pca_axes)\n",
    "    \n",
    "    # Tier 2: Add candidates from pairwise voting.\n",
    "    if use_voting:\n",
    "        voted_normals = find_candidate_normals_via_voting(centered_points)\n",
    "        candidate_normals.extend(voted_normals)\n",
    "    \n",
    "    # Remove near-duplicate normals before testing.\n",
    "    # This avoids re-testing very similar planes.\n",
    "    unique_normals_set = {tuple(row) for row in np.round(candidate_normals, 2)}\n",
    "    unique_normals = [np.array(t) for t in unique_normals_set]\n",
    "    print(f\"   - Testing a total of {len(unique_normals)} unique candidate planes.\")\n",
    "\n",
    "    # --- Testing and Scoring ---\n",
    "    best_reflection = {'score': float('inf')}\n",
    "    print(\"   --- Testing Reflectional Symmetry ---\")\n",
    "    for i, normal in enumerate(unique_normals):\n",
    "        print(f\"   -> Testing candidate plane #{i+1}...\")\n",
    "        result = _score_reflection_plane_robust(points, point_tree, normal, centroid, match_threshold)\n",
    "        \n",
    "        # This check is now inside the loop for clarity.\n",
    "        if result is not None and 'score' in result:\n",
    "             print(f\"      [DEBUG] Result: Score={result['score']:.4f}, Inlier Ratio={result['inlier_ratio']:.2%}, Mean Error={result['mean_error']:.4f}m\")\n",
    "             if result['score'] < best_reflection['score']:\n",
    "                best_reflection = result\n",
    "                best_reflection['plane_normal'] = normal.tolist()\n",
    "\n",
    "    # --- Final Decision ---\n",
    "    print(\"   --- Final Decision ---\")\n",
    "    best_inlier_ratio = best_reflection.get('inlier_ratio', 0)\n",
    "    print(f\"   [DEBUG] Best inlier ratio found: {best_inlier_ratio:.2%}. Required minimum: {min_inlier_ratio:.2%}\")\n",
    "    \n",
    "    if best_inlier_ratio > min_inlier_ratio:\n",
    "        print(f\"   SUCCESS: Found reflectional symmetry that meets the criteria!\")\n",
    "        reflection_result = {\n",
    "            'type': 'reflectional',\n",
    "            'score': best_reflection['score'],\n",
    "            'inlier_ratio': best_reflection['inlier_ratio'],\n",
    "            'mean_inlier_error': best_reflection['mean_error'],\n",
    "            'plane_point': centroid.tolist(),\n",
    "            'plane_normal': best_reflection['plane_normal']\n",
    "        }\n",
    "        vignette.add_abstraction('symmetries', reflection_result, auto_save=False)\n",
    "    else:\n",
    "        print(\"   - No reflectional symmetry found that passed the minimum inlier ratio threshold.\")\n",
    "    \n",
    "    print(\"Finished symmetry analysis.\")\n",
    "    if auto_save and vignette.file_path:\n",
    "        vignette.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a55b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing global symmetry (robust method)...\n",
      "   [DEBUG] Initial point count: 8971\n",
      "   [DEBUG] Non-noise point count: 8971\n",
      "      [DEBUG] Starting pairwise voting to find more candidate planes...\n",
      "      [DEBUG] Top accumulator votes: [np.float64(41.0), np.float64(42.0), np.float64(52.0)]\n",
      "   - Testing a total of 6 unique candidate planes.\n",
      "   --- Testing Reflectional Symmetry ---\n",
      "   -> Testing candidate plane #1...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 3057 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 269 / 3057\n",
      "      [DEBUG] Result: Score=0.0482, Inlier Ratio=3.00%, Mean Error=0.0014m\n",
      "   -> Testing candidate plane #2...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 6887 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 1243 / 6887\n",
      "      [DEBUG] Result: Score=0.0144, Inlier Ratio=13.86%, Mean Error=0.0020m\n",
      "   -> Testing candidate plane #3...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 7295 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 1126 / 7295\n",
      "      [DEBUG] Result: Score=0.0160, Inlier Ratio=12.55%, Mean Error=0.0020m\n",
      "   -> Testing candidate plane #4...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 8643 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 1837 / 8643\n",
      "      [DEBUG] Result: Score=0.0070, Inlier Ratio=20.48%, Mean Error=0.0014m\n",
      "   -> Testing candidate plane #5...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 8684 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 801 / 8684\n",
      "      [DEBUG] Result: Score=0.0177, Inlier Ratio=8.93%, Mean Error=0.0016m\n",
      "   -> Testing candidate plane #6...\n",
      "      [DEBUG] Potential inliers found (distance < 0.03m): 7525 / 8971\n",
      "      [DEBUG] Consistent inliers found (passed backward check): 1014 / 7525\n",
      "      [DEBUG] Result: Score=0.0146, Inlier Ratio=11.30%, Mean Error=0.0016m\n",
      "   --- Final Decision ---\n",
      "   [DEBUG] Best inlier ratio found: 20.48%. Required minimum: 50.00%\n",
      "   - No reflectional symmetry found that passed the minimum inlier ratio threshold.\n",
      "Finished symmetry analysis.\n"
     ]
    }
   ],
   "source": [
    "analyze_global_symmetry(\n",
    "    vignette=processed_vignette, \n",
    "    match_threshold=0.03, \n",
    "    min_inlier_ratio=0.5,\n",
    "    use_voting=True,\n",
    "    auto_save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9865d",
   "metadata": {},
   "source": [
    "## Inter Primitive Relations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7861b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "# This assumes your ProcessedVignette class is defined elsewhere and has\n",
    "# the methods get_abstractions and add_abstraction.\n",
    "\n",
    "def analyze_primitive_relations(\n",
    "    vignette: 'ProcessedVignette',\n",
    "    angle_tolerance_deg: float = 5.0,\n",
    "    distance_tolerance_m: float = 0.01,\n",
    "    auto_save: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Analyzes and stores geometric relationships between primitives in a vignette.\n",
    "    \n",
    "    This version supports:\n",
    "    - Plane-Plane: Parallelism, Perpendicularity, Co-planarity, Distance.\n",
    "    - Cylinder-Cylinder: Parallelism, Perpendicularity.\n",
    "    \n",
    "    (Includes detailed debug logging).\n",
    "    \"\"\"\n",
    "    print(\"Analyzing primitive relationships...\")\n",
    "    vignette.clear_abstractions('primitive_relations', auto_save=False)\n",
    "    \n",
    "    # --- Calculate tolerance values from degrees ---\n",
    "    # cos(angle) for parallel check. Angle is close to 0 or 180.\n",
    "    parallel_dot_threshold = np.cos(np.deg2rad(angle_tolerance_deg))\n",
    "    # cos(angle) for perpendicular check. Angle is close to 90.\n",
    "    perp_dot_threshold = np.cos(np.deg2rad(90 - angle_tolerance_deg))\n",
    "    \n",
    "    print(f\"   [DEBUG] Angle tolerance: {angle_tolerance_deg}Â°\")\n",
    "    print(f\"   [DEBUG] Parallel check: dot product must be > {parallel_dot_threshold:.4f}\")\n",
    "    print(f\"   [DEBUG] Perpendicular check: dot product must be < {perp_dot_threshold:.4f}\")\n",
    "\n",
    "    # --- Retrieve all primitives at the start ---\n",
    "    planes = vignette.get_abstractions('planes') or []\n",
    "    cylinders = vignette.get_abstractions('cylinders') or []\n",
    "\n",
    "    # --- 1. Analyze Plane-Plane Relationships ---\n",
    "    if len(planes) < 2:\n",
    "        print(\"\\n   - Skipping plane-plane analysis (less than 2 planes found).\")\n",
    "    else:\n",
    "        print(f\"\\n   --- Analyzing {len(planes)} Plane-Plane pairs ---\")\n",
    "        for plane1, plane2 in itertools.combinations(planes, 2):\n",
    "            id1 = plane1['plane_id']\n",
    "            id2 = plane2['plane_id']\n",
    "            \n",
    "            print(f\"\\n   -> Comparing plane_{id1} and plane_{id2}...\")\n",
    "\n",
    "            # Extract and normalize normal vectors\n",
    "            n1 = np.array(plane1['equation'][:3]); n1 /= np.linalg.norm(n1)\n",
    "            n2 = np.array(plane2['equation'][:3]); n2 /= np.linalg.norm(n2)\n",
    "            dot_product = np.abs(np.dot(n1, n2))\n",
    "            \n",
    "            print(f\"      [DEBUG] Normalized dot product: {dot_product:.4f}\")\n",
    "\n",
    "            # Check for Parallelism\n",
    "            if dot_product > parallel_dot_threshold:\n",
    "                print(f\"      [DEBUG] Test PASS: {dot_product:.4f} > {parallel_dot_threshold:.4f} (Parallel)\")\n",
    "                \n",
    "                # Find a point on plane 1 to calculate distance\n",
    "                eq1 = plane1['equation']\n",
    "                if abs(eq1[2]) > 1e-6: p1 = np.array([0, 0, -eq1[3]/eq1[2]])\n",
    "                elif abs(eq1[1]) > 1e-6: p1 = np.array([0, -eq1[3]/eq1[1], 0])\n",
    "                else: p1 = np.array([-eq1[3]/eq1[0], 0, 0])\n",
    "                \n",
    "                eq2 = plane2['equation']\n",
    "                distance = np.abs(np.dot(p1, eq2[:3]) + eq2[3]) / np.linalg.norm(eq2[:3])\n",
    "                print(f\"      [DEBUG] Distance between planes: {distance:.4f}m\")\n",
    "\n",
    "                relation_type = \"co-planar\" if distance < distance_tolerance_m else \"parallel\"\n",
    "                print(f\"      -> SUCCESS: Found '{relation_type.upper()}' relationship.\")\n",
    "                \n",
    "                relation = {\n",
    "                    'type': relation_type,\n",
    "                    'primitives': [f'plane_{id1}', f'plane_{id2}'],\n",
    "                    'angle_diff_deg': np.rad2deg(np.arccos(dot_product)),\n",
    "                    'distance_m': distance if relation_type == 'parallel' else 0.0\n",
    "                }\n",
    "                vignette.add_abstraction('primitive_relations', relation, auto_save=False)\n",
    "\n",
    "            # Check for Perpendicularity\n",
    "            elif dot_product < perp_dot_threshold:\n",
    "                print(f\"      [DEBUG] Test PASS: {dot_product:.4f} < {perp_dot_threshold:.4f} (Perpendicular)\")\n",
    "                print(f\"      -> SUCCESS: Found 'PERPENDICULAR' relationship.\")\n",
    "                relation = {\n",
    "                    'type': 'perpendicular',\n",
    "                    'primitives': [f'plane_{id1}', f'plane_{id2}'],\n",
    "                    'angle_diff_deg': 90.0 - np.rad2deg(np.arcsin(dot_product))\n",
    "                }\n",
    "                vignette.add_abstraction('primitive_relations', relation, auto_save=False)\n",
    "            \n",
    "            else:\n",
    "                 print(f\"      [DEBUG] Test FAIL: No significant relationship found.\")\n",
    "\n",
    "    # --- 2. Analyze Cylinder-Cylinder Relationships ---\n",
    "    if len(cylinders) < 2:\n",
    "        print(\"\\n   - Skipping cylinder-cylinder analysis (less than 2 cylinders found).\")\n",
    "    else:\n",
    "        print(f\"\\n   --- Analyzing {len(cylinders)} Cylinder-Cylinder pairs ---\")\n",
    "        for cyl1, cyl2 in itertools.combinations(cylinders, 2):\n",
    "            id1 = cyl1['cylinder_id']\n",
    "            id2 = cyl2['cylinder_id']\n",
    "            print(f\"\\n   -> Comparing cylinder_{id1} and cylinder_{id2}...\")\n",
    "            \n",
    "            a1 = np.array(cyl1['axis']); a1 /= np.linalg.norm(a1)\n",
    "            a2 = np.array(cyl2['axis']); a2 /= np.linalg.norm(a2)\n",
    "            dot_product = np.abs(np.dot(a1, a2))\n",
    "            print(f\"      [DEBUG] Normalized dot product: {dot_product:.4f}\")\n",
    "            \n",
    "            if dot_product > parallel_dot_threshold:\n",
    "                print(f\"      -> SUCCESS: Found 'PARALLEL' relationship.\")\n",
    "                relation = {'type': 'parallel', 'primitives': [f'cylinder_{id1}', f'cylinder_{id2}']}\n",
    "                vignette.add_abstraction('primitive_relations', relation, auto_save=False)\n",
    "            elif dot_product < perp_dot_threshold:\n",
    "                print(f\"      -> SUCCESS: Found 'PERPENDICULAR' relationship.\")\n",
    "                relation = {'type': 'perpendicular', 'primitives': [f'cylinder_{id1}', f'cylinder_{id2}']}\n",
    "                vignette.add_abstraction('primitive_relations', relation, auto_save=False)\n",
    "            else:\n",
    "                print(f\"      [DEBUG] Test FAIL: No significant relationship found.\")\n",
    "                \n",
    "    if auto_save and vignette.file_path:\n",
    "        vignette.save()\n",
    "    print(\"\\nFinished analyzing primitive relationships.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5f087b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing primitive relationships...\n",
      "Cleared 3 abstractions of type 'primitive_relations'.\n",
      "   [DEBUG] Angle tolerance: 8.0Â°\n",
      "   [DEBUG] Parallel check: dot product must be > 0.9903\n",
      "   [DEBUG] Perpendicular check: dot product must be < 0.1392\n",
      "\n",
      "   --- Analyzing 7 Plane-Plane pairs ---\n",
      "\n",
      "   -> Comparing plane_1 and plane_2...\n",
      "      [DEBUG] Normalized dot product: 0.4833\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_1 and plane_3...\n",
      "      [DEBUG] Normalized dot product: 0.4043\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_1 and plane_4...\n",
      "      [DEBUG] Normalized dot product: 0.4607\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_1 and plane_5...\n",
      "      [DEBUG] Normalized dot product: 0.2775\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_1 and plane_6...\n",
      "      [DEBUG] Normalized dot product: 0.1408\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_1 and plane_7...\n",
      "      [DEBUG] Normalized dot product: 0.9997\n",
      "      [DEBUG] Test PASS: 0.9997 > 0.9903 (Parallel)\n",
      "      [DEBUG] Distance between planes: 0.0063m\n",
      "      -> SUCCESS: Found 'PARALLEL' relationship.\n",
      "Added new abstraction of type 'primitive_relations'.\n",
      "\n",
      "   -> Comparing plane_2 and plane_3...\n",
      "      [DEBUG] Normalized dot product: 0.9460\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_2 and plane_4...\n",
      "      [DEBUG] Normalized dot product: 0.9995\n",
      "      [DEBUG] Test PASS: 0.9995 > 0.9903 (Parallel)\n",
      "      [DEBUG] Distance between planes: 0.0071m\n",
      "      -> SUCCESS: Found 'PARALLEL' relationship.\n",
      "Added new abstraction of type 'primitive_relations'.\n",
      "\n",
      "   -> Comparing plane_2 and plane_5...\n",
      "      [DEBUG] Normalized dot product: 0.2632\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_2 and plane_6...\n",
      "      [DEBUG] Normalized dot product: 0.2621\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_2 and plane_7...\n",
      "      [DEBUG] Normalized dot product: 0.5034\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_3 and plane_4...\n",
      "      [DEBUG] Normalized dot product: 0.9538\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_3 and plane_5...\n",
      "      [DEBUG] Normalized dot product: 0.5465\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_3 and plane_6...\n",
      "      [DEBUG] Normalized dot product: 0.5542\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_3 and plane_7...\n",
      "      [DEBUG] Normalized dot product: 0.4214\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_4 and plane_5...\n",
      "      [DEBUG] Normalized dot product: 0.2926\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_4 and plane_6...\n",
      "      [DEBUG] Normalized dot product: 0.2819\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_4 and plane_7...\n",
      "      [DEBUG] Normalized dot product: 0.4809\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_5 and plane_6...\n",
      "      [DEBUG] Normalized dot product: 0.8786\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_5 and plane_7...\n",
      "      [DEBUG] Normalized dot product: 0.2739\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing plane_6 and plane_7...\n",
      "      [DEBUG] Normalized dot product: 0.1378\n",
      "      [DEBUG] Test PASS: 0.1378 < 0.1392 (Perpendicular)\n",
      "      -> SUCCESS: Found 'PERPENDICULAR' relationship.\n",
      "Added new abstraction of type 'primitive_relations'.\n",
      "\n",
      "   --- Analyzing 3 Cylinder-Cylinder pairs ---\n",
      "\n",
      "   -> Comparing cylinder_1 and cylinder_2...\n",
      "      [DEBUG] Normalized dot product: 0.3312\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing cylinder_1 and cylinder_3...\n",
      "      [DEBUG] Normalized dot product: 0.2979\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "   -> Comparing cylinder_2 and cylinder_3...\n",
      "      [DEBUG] Normalized dot product: 0.6195\n",
      "      [DEBUG] Test FAIL: No significant relationship found.\n",
      "\n",
      "Finished analyzing primitive relationships.\n"
     ]
    }
   ],
   "source": [
    "analyze_primitive_relations(\n",
    "    vignette=processed_vignette,\n",
    "    angle_tolerance_deg=8.0,\n",
    "    distance_tolerance_m=0.002,\n",
    "    auto_save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf871bbb",
   "metadata": {},
   "source": [
    "## Point-wise features ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d83ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "def analyze_local_features(\n",
    "    vignette: 'ProcessedVignette',\n",
    "    search_radius: float = 0.05,\n",
    "    max_neighbors: int = 30,\n",
    "    auto_save: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Analyzes per-point local geometric features like normals, curvature, and edgeness.\n",
    "\n",
    "    This version manually computes covariance for robustness across Open3D versions.\n",
    "\n",
    "    Args:\n",
    "        vignette: The vignette to analyze. It will be modified in-place.\n",
    "        search_radius: The radius (in meters) to search for neighbors.\n",
    "        max_neighbors: The maximum number of neighbors to consider in the radius search.\n",
    "        auto_save: If True, saves the vignette after modification.\n",
    "    \"\"\"\n",
    "    print(\"Analyzing local geometric features (normals, curvature, etc.)...\")\n",
    "    \n",
    "    # 1. Convert to Open3D PointCloud and estimate normals (this part is fine)\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(vignette.points)\n",
    "    \n",
    "    search_param = o3d.geometry.KDTreeSearchParamHybrid(radius=search_radius, max_nn=max_neighbors)\n",
    "    print(f\"   - Estimating normals with radius={search_radius}m and max_neighbors={max_neighbors}...\")\n",
    "    pcd.estimate_normals(search_param=search_param)\n",
    "    pcd.orient_normals_consistent_tangent_plane(k=max_neighbors)\n",
    "    \n",
    "    vignette.normals = np.asarray(pcd.normals)\n",
    "    print(\"   - Stored surface normals.\")\n",
    "\n",
    "    # --- CORRECTED SECTION: Manual Covariance, Curvature, and Edgeness Calculation ---\n",
    "    print(\"   - Estimating curvature and edgeness...\")\n",
    "    \n",
    "    # 2. Build a K-D Tree for efficient neighbor searches\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    \n",
    "    # Initialize arrays to hold the new per-point data\n",
    "    curvatures = np.zeros(vignette.n_points)\n",
    "    edgeness = np.zeros(vignette.n_points)\n",
    "    \n",
    "    # 3. Loop through each point to analyze its neighborhood\n",
    "    points = np.asarray(pcd.points)\n",
    "    for i in range(vignette.n_points):\n",
    "        # Find neighbors of the i-th point\n",
    "        [k, idx, _] = pcd_tree.search_radius_vector_3d(points[i], search_radius)\n",
    "        \n",
    "        # We need at least 4 points (the point itself + 3 others) to compute a meaningful covariance\n",
    "        if k < 4:\n",
    "            continue\n",
    "\n",
    "        # Get the actual 3D coordinates of the neighboring points\n",
    "        neighbors = points[idx, :]\n",
    "        \n",
    "        # Compute the 3x3 covariance matrix for the neighborhood\n",
    "        # np.cov expects variables as rows, so we need to transpose the (k, 3) matrix to (3, k)\n",
    "        cov_matrix = np.cov(neighbors.T)\n",
    "        \n",
    "        # Eigen-decomposition of the covariance matrix\n",
    "        eigenvalues, _ = np.linalg.eigh(cov_matrix)\n",
    "        \n",
    "        # Sort eigenvalues: l1 >= l2 >= l3\n",
    "        l1, l2, l3 = eigenvalues[2], eigenvalues[1], eigenvalues[0]\n",
    "        \n",
    "        sum_eigenvalues = l1 + l2 + l3\n",
    "        if sum_eigenvalues < 1e-9:\n",
    "            continue\n",
    "\n",
    "        # Curvature calculation\n",
    "        curvatures[i] = l3 / sum_eigenvalues\n",
    "        \n",
    "        # Edgeness/Linearity calculation\n",
    "        if l1 > 1e-9:\n",
    "            edgeness[i] = (l1 - l2) / l1\n",
    "\n",
    "    # 4. Store the new attributes in the vignette\n",
    "    vignette.set_attribute('curvature', curvatures, auto_save=False)\n",
    "    vignette.set_attribute('edgeness', edgeness, auto_save=False)\n",
    "    \n",
    "    if auto_save and vignette.file_path:\n",
    "        vignette.save()\n",
    "        \n",
    "    print(\"Finished analyzing local features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408f0083",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_vignette' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m analyze_local_features(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mprocessed_vignette\u001b[49m, \n\u001b[32m      3\u001b[39m     search_radius=\u001b[32m0.03\u001b[39m, \n\u001b[32m      4\u001b[39m     auto_save=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'processed_vignette' is not defined"
     ]
    }
   ],
   "source": [
    "analyze_local_features(\n",
    "    processed_vignette, \n",
    "    search_radius=0.03, \n",
    "    auto_save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a78c7",
   "metadata": {},
   "source": [
    "## Point-Wise Features From 3D Points ##\n",
    "\n",
    "This should be a more recent version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d895dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set/updated per-point attribute: 'confidence'.\n",
      "Set/updated per-point attribute: 'plane_id'.\n",
      "Set/updated per-point attribute: 'cylinder_id'.\n",
      "Set/updated per-point attribute: 'sphere_id'.\n",
      "Set/updated per-point attribute: 'cuboid_id'.\n",
      "Set/updated per-point attribute: 'component_id'.\n",
      "Set/updated per-point attribute: 'best_fit_id'.\n",
      "Set/updated per-point attribute: 'curvature'.\n",
      "Set/updated per-point attribute: 'edgeness'.\n",
      "Set/updated per-point attribute: 'anisotropy'.\n",
      "Set/updated per-point attribute: 'planarity'.\n",
      "Set/updated per-point attribute: 'sphericity'.\n",
      "Set/updated per-point attribute: 'flow_vectors'.\n",
      "Loaded processed vignette from: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/results/processed_vignette.npz\n"
     ]
    }
   ],
   "source": [
    "processed_vignette_path = results_path / \"processed_vignette.npz\"\n",
    "from pipeline.vignette_data import ProcessedVignette\n",
    "processed_vignette = ProcessedVignette.load(processed_vignette_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d703db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_local_features(\n",
    "    vignette: 'ProcessedVignette',\n",
    "    search_radius: float = 0.05,\n",
    "    max_neighbors: int = 30,\n",
    "    auto_save: bool = False\n",
    ") -> None:\n",
    "    # --- (Same setup as before) ---\n",
    "    print(\"Analyzing rich local geometric features...\")\n",
    "    pcd = o3d.geometry.PointCloud(); pcd.points = o3d.utility.Vector3dVector(vignette.points)\n",
    "    search_param = o3d.geometry.KDTreeSearchParamHybrid(radius=search_radius, max_nn=max_neighbors)\n",
    "    pcd.estimate_normals(search_param=search_param)\n",
    "    pcd.orient_normals_consistent_tangent_plane(k=max_neighbors)\n",
    "    vignette.normals = np.asarray(pcd.normals)\n",
    "    \n",
    "    print(\"   - Estimating per-point geometric features...\")\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    points = np.asarray(pcd.points)\n",
    "    n_points = vignette.n_points\n",
    "    \n",
    "    # Initialize arrays\n",
    "    curvatures, edgeness, anisotropy, planarity, sphericity = (np.zeros(n_points) for _ in range(5))\n",
    "    flow_vectors = np.zeros((n_points, 3)) # NEW: Array to store the flow vectors\n",
    "    \n",
    "    for i in range(n_points):\n",
    "        [k, idx, _] = pcd_tree.search_radius_vector_3d(points[i], search_radius)\n",
    "        if k < 5: continue\n",
    "        \n",
    "        neighbors = points[idx, :]\n",
    "        cov_matrix = np.cov(neighbors.T)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "        \n",
    "        # Sort eigenvalues and corresponding eigenvectors\n",
    "        sort_indices = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[sort_indices]\n",
    "        eigenvectors = eigenvectors[:, sort_indices]\n",
    "        \n",
    "        l1, l2, l3 = eigenvalues\n",
    "        v1, _, _ = eigenvectors.T\n",
    "\n",
    "        # --- NEW: Store the primary eigenvector as the flow vector ---\n",
    "        flow_vectors[i] = v1\n",
    "\n",
    "        # (Rest of the calculations for scalar features are the same)\n",
    "        # ...\n",
    "        sum_eigenvalues = l1 + l2 + l3\n",
    "        if sum_eigenvalues < 1e-9: continue\n",
    "        curvatures[i] = l3 / sum_eigenvalues\n",
    "        if l1 > 1e-9:\n",
    "            edgeness[i] = (l1 - l2) / l1\n",
    "            anisotropy[i] = (l1 - l3) / l1\n",
    "            planarity[i] = (l2 - l3) / l1\n",
    "            sphericity[i] = l3 / l1\n",
    "            \n",
    "    # Store all attributes\n",
    "    vignette.set_attribute('curvature', curvatures, auto_save=False)\n",
    "    vignette.set_attribute('edgeness', edgeness, auto_save=False)\n",
    "    vignette.set_attribute('anisotropy', anisotropy, auto_save=False)\n",
    "    vignette.set_attribute('planarity', planarity, auto_save=False)\n",
    "    vignette.set_attribute('sphericity', sphericity, auto_save=False)\n",
    "    vignette.set_attribute('flow_vectors', flow_vectors, auto_save=False) # NEW\n",
    "    \n",
    "    if auto_save and vignette.file_path: vignette.save()\n",
    "    print(\"Finished analyzing local features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5986cc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing rich local geometric features...\n",
      "   - Estimating per-point geometric features...\n",
      "Set/updated per-point attribute: 'curvature'.\n",
      "Set/updated per-point attribute: 'edgeness'.\n",
      "Set/updated per-point attribute: 'anisotropy'.\n",
      "Set/updated per-point attribute: 'planarity'.\n",
      "Set/updated per-point attribute: 'sphericity'.\n",
      "Set/updated per-point attribute: 'flow_vectors'.\n",
      "Saved processed vignette to: /Users/yuzhenzhang/Documents/Research/TestApp/SpatialVignetteServer/test_data/capture2/results/processed_vignette.npz\n",
      "Finished analyzing local features.\n"
     ]
    }
   ],
   "source": [
    "analyze_local_features(\n",
    "    processed_vignette, \n",
    "    search_radius=0.03, \n",
    "    max_neighbors=30,\n",
    "    auto_save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63582515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing Curvature...\n",
      "Generating Open3D point cloud with 'curvature' colors...\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# Assume 'processed_vignette' is loaded and has had analyze_local_features() run on it.\n",
    "\n",
    "# 1. Visualize Curvature\n",
    "# Bright yellow areas = sharp corners, bends, and noisy points.\n",
    "# Deep blue areas = flat surfaces.\n",
    "print(\"Visualizing Curvature...\")\n",
    "o3d.visualization.draw_geometries([processed_vignette.to_open3d(color_mode='curvature')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54c27e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing Edgeness...\n",
      "Generating Open3D point cloud with 'edgeness' colors...\n"
     ]
    }
   ],
   "source": [
    "# 2. Visualize Edgeness (Linearity)\n",
    "# Bright yellow areas = sharp creases, like the edge of a box or a fold.\n",
    "print(\"Visualizing Edgeness...\")\n",
    "o3d.visualization.draw_geometries([processed_vignette.to_open3d(color_mode='edgeness')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75edff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing Anisotropy...\n",
      "Generating Open3D point cloud with 'anisotropy' colors...\n"
     ]
    }
   ],
   "source": [
    "# 3. Visualize Anisotropy\n",
    "# Bright yellow areas = surfaces with a strong directional \"flow\" or \"grain\", like a cylinder.\n",
    "print(\"Visualizing Anisotropy...\")\n",
    "o3d.visualization.draw_geometries([processed_vignette.to_open3d(color_mode='anisotropy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97030f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing Planarity...\n",
      "Generating Open3D point cloud with 'planarity' colors...\n"
     ]
    }
   ],
   "source": [
    "# 4. Visualize Planarity\n",
    "# Bright yellow areas = flat planes. This is great for confirming the results of RANSAC.\n",
    "print(\"Visualizing Planarity...\")\n",
    "o3d.visualization.draw_geometries([processed_vignette.to_open3d(color_mode='planarity')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1378cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing Sphericity...\n",
      "Generating Open3D point cloud with 'sphericity' colors...\n"
     ]
    }
   ],
   "source": [
    "# 5. Visualize Sphericity\n",
    "# Bright yellow areas = complex, non-directional geometry or noisy point clusters.\n",
    "print(\"Visualizing Sphericity...\")\n",
    "o3d.visualization.draw_geometries([processed_vignette.to_open3d(color_mode='sphericity')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b90c7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_vector_attribute(\n",
    "    vignette: 'ProcessedVignette',\n",
    "    attribute_name: str,\n",
    "    step: int = 20,\n",
    "    scale: float = 0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes a per-point vector attribute (e.g., normals) as lines.\n",
    "\n",
    "    Args:\n",
    "        vignette: The processed vignette containing the attribute.\n",
    "        attribute_name: The name of the vector attribute to draw (e.g., 'normals', 'flow_vectors').\n",
    "        step: Draws a vector for every 'step' points to avoid clutter. 1 = all points.\n",
    "        scale: The visual length of the lines drawn in the plot.\n",
    "    \"\"\"\n",
    "    print(f\"Visualizing vector attribute: '{attribute_name}'...\")\n",
    "    \n",
    "    pcd = vignette.to_open3d() # Get the base point cloud\n",
    "    vectors = vignette.get_attribute(attribute_name)\n",
    "    \n",
    "    if vectors is None:\n",
    "        print(f\"Error: Attribute '{attribute_name}' not found in vignette.\")\n",
    "        return\n",
    "        \n",
    "    # Subsample points to avoid a cluttered visualization\n",
    "    points_subset = vignette.points[::step]\n",
    "    vectors_subset = vectors[::step]\n",
    "    \n",
    "    # Create LineSet geometry\n",
    "    lines = []\n",
    "    points_for_lines = []\n",
    "    for i in range(len(points_subset)):\n",
    "        p = points_subset[i]\n",
    "        vec = vectors_subset[i]\n",
    "        \n",
    "        # The line starts at the point and ends at point + scaled vector\n",
    "        start_point = p\n",
    "        end_point = p + vec * scale\n",
    "        \n",
    "        # Add the two points and the line connecting them\n",
    "        points_for_lines.append(start_point)\n",
    "        points_for_lines.append(end_point)\n",
    "        lines.append([2*i, 2*i + 1])\n",
    "        \n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points_for_lines),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "    )\n",
    "    # Optional: Color the lines\n",
    "    line_set.paint_uniform_color([1.0, 0.0, 0.0]) # Red lines\n",
    "    \n",
    "    # Draw the original point cloud AND the lines on top\n",
    "    o3d.visualization.draw_geometries([pcd, line_set])\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# 1. First, make sure you've run the updated analysis function\n",
    "# analyze_local_features(processed_vignette, auto_save=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7bd374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing vector attribute: 'flow_vectors'...\n",
      "Generating Open3D point cloud with 'rgb' colors...\n"
     ]
    }
   ],
   "source": [
    "visualize_vector_attribute(processed_vignette, 'flow_vectors', step=1, scale=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
